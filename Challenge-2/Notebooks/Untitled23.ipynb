{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms, datasets, models\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from PIL import Image\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "x1c2Jpa9d6G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Data Transforms ---------\n",
        "train_transform = transforms.Compose([\n",
        "transforms.Resize((224, 224)),\n",
        "transforms.RandomHorizontalFlip(),\n",
        "transforms.RandomRotation(15),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "P2qp_3XBd-A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_transform = transforms.Compose([\n",
        "transforms.Resize((224, 224)),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = val_transform # Same as validation"
      ],
      "metadata": {
        "id": "mQXhukAYeA5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Paths (update these) ---------\n",
        "train_dir = '/kaggle/input/binary-data-2/Dataset2' # Folder with only soil images\n",
        "test_dir = '/kaggle/input/binary-data-2/ttest3' # Contains both soil and non-soil"
      ],
      "metadata": {
        "id": "0JjMuM7leITL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Custom Dataset for Binary Classification ---------\n",
        "class BinarySoilDataset(datasets.ImageFolder):\n",
        "def _init_(self, root, transform=None, is_train=True):\n",
        "super()._init_(root, transform=transform)\n",
        "self.is_train = is_train\n",
        "\n",
        "def _getitem_(self, index):\n",
        "img, _ = super()._getitem_(index)\n",
        "if self.is_train:\n",
        "return img, torch.tensor(1, dtype=torch.long)\n",
        "else:\n",
        "path, _ = self.samples[index]\n",
        "label = 1 if any(soil_type in path for soil_type in self.classes) else 0\n",
        "return img, torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "FyrfcwtFeJP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Load Datasets ---------\n",
        "train_dataset = BinarySoilDataset(root=train_dir, transform=train_transform, is_train=True)\n",
        "test_dataset = BinarySoilDataset(root=test_dir, transform=test_transform, is_train=False)"
      ],
      "metadata": {
        "id": "2A_hF2UMeLeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train into train and val\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "val_dataset.dataset.transform = val_transform"
      ],
      "metadata": {
        "id": "r3Di3zGieOnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- DataLoaders ---------\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
      ],
      "metadata": {
        "id": "JlQHAxA9eQxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Device ---------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "GPJSusbNeSPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- ResNet50 Model for Binary Classification ---------\n",
        "def get_resnet50_binary():\n",
        "model = models.resnet50(pretrained=True)\n",
        "for param in model.parameters():\n",
        "param.requires_grad = False\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "nn.Linear(num_ftrs, 512),\n",
        "nn.ReLU(True),\n",
        "nn.Dropout(0.5),\n",
        "nn.Linear(512, 2)\n",
        ")\n",
        "for param in model.layer4.parameters():\n",
        "param.requires_grad = True\n",
        "return model\n",
        "\n",
        "model = get_resnet50_binary().to(device)\n"
      ],
      "metadata": {
        "id": "MtaxYj5jeT1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Loss and Optimizer ---------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "sPLd6OwneYof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Training Function ---------\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "model.train()\n",
        "running_loss = 0.0\n",
        "for images, labels in dataloader:\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "optimizer.zero_grad()\n",
        "outputs = model(images)\n",
        "loss = criterion(outputs, labels)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "running_loss += loss.item() * images.size(0)\n",
        "return running_loss / len(dataloader.dataset)"
      ],
      "metadata": {
        "id": "Qlx6EcPzegV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Evaluation Function ---------\n",
        "def evaluate(model, dataloader, device):\n",
        "model.eval()\n",
        "preds, targets = [], []\n",
        "with torch.no_grad():\n",
        "for images, labels in dataloader:\n",
        "images = images.to(device)\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "preds.extend(predicted.cpu().numpy())\n",
        "targets.extend(labels.cpu().numpy())\n",
        "acc = accuracy_score(targets, preds)\n",
        "f1 = f1_score(targets, preds, average='binary')\n",
        "return acc, f1"
      ],
      "metadata": {
        "id": "tQBXLT-Mein2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Main Training Loop ---------\n",
        "num_epochs = 8\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "val_acc, val_f1 = evaluate(model, val_loader, device)\n",
        "print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Val Acc: {val_acc*100:.2f}%, Val F1: {val_f1:.4f}\")\n",
        "if val_acc > best_val_acc:\n",
        "best_val_acc = val_acc\n",
        "torch.save(model.state_dict(), 'best_soil_classifier.pth')\n"
      ],
      "metadata": {
        "id": "1sn3uq3Jekhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model for testing\n",
        "model.load_state_dict(torch.load('best_soil_classifier.pth'))\n"
      ],
      "metadata": {
        "id": "NV4u7CI2emaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Test Evaluation ---------\n",
        "test_acc, test_f1 = evaluate(model, test_loader, device)\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc*100:.2f}%\")\n",
        "print(f\"Final Test F1 Score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "5-0u2kRIeodS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Predict and Save to CSV ---------\n",
        "model.eval()\n",
        "image_paths = [s[0] for s in test_dataset.samples]\n",
        "predictions = []"
      ],
      "metadata": {
        "id": "NI-yYzaZetU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "for img_path in image_paths:\n",
        "img = Image.open(img_path).convert('RGB')\n",
        "img = test_transform(img).unsqueeze(0).to(device)\n",
        "output = model(img)\n",
        "_, pred = torch.max(output, 1)\n",
        "predictions.append((os.path.basename(img_path), pred.item()))\n"
      ],
      "metadata": {
        "id": "A2gZLKc6euuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km2YrUBid32e"
      },
      "outputs": [],
      "source": [
        "# Create and save CSV\n",
        "df = pd.DataFrame(predictions, columns=[\"image_id\", \"label\"])\n",
        "df.to_csv(\"test_predictions.csv\", index=False)\n",
        "print(\"\\nPredictions saved to test_predictions.csv\") generate an image on the model architecture"
      ]
    }
  ]
}